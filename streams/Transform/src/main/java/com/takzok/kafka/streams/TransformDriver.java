/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package com.takzok.kafka.streams;

import java.io.FileReader;
import java.io.IOException;
import java.io.InputStream;
import java.io.Reader;
import java.util.Properties;

import org.apache.avro.Schema;
import org.apache.avro.generic.GenericData;
import org.apache.avro.generic.GenericRecord;
import org.apache.avro.generic.GenericRecordBuilder;
import org.apache.commons.csv.CSVFormat;
import org.apache.commons.csv.CSVRecord;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.clients.producer.ProducerRecord;

import io.confluent.kafka.serializers.AbstractKafkaAvroSerDeConfig;

public class TransformDriver {
  public static void main(String[] args) throws IOException {
    final String bootstrapServers = args.length > 0 ? args[0] : "localhost:9092";
    final String schemaRegistryUrl = args.length > 1 ? args[1] : "http://localhost:8081";
    produceInputs(bootstrapServers, schemaRegistryUrl);
    consumeOutput(bootstrapServers);
  }

  private static void consumeOutput(String bootstrapServers) {

  }

  private static void produceInputs(String bootstrapServers, String schemaRegistryUrl) throws IOException {
    final Properties props = new Properties();
    props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);
    props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.StringSerializer");
    props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, "io.confluent.kafka.serializers.KafkaAvroSerializer");
    props.put(AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, schemaRegistryUrl);

    final GenericRecordBuilder nycHostBuilder = new GenericRecordBuilder(loadSchema("abnychost.avsc"));
    final GenericRecordBuilder nycRoomBuilder = new GenericRecordBuilder(loadSchema("abnycroom.avsc"));

    final String nycHostsTopic = "NYCHosts";
    final String nycRoomsTopic = "NYCRooms";


    try (final KafkaProducer<String, GenericRecord> producer = new KafkaProducer<>(props)) {
      /**
       * Produce airbnb host information record to NYChosts topic. Read each line in
       * abnychost.csv and parse records.
       */
      Reader hostReader = new FileReader("./resources/ab-nyc/ab-nyc-2019-host.csv");
      Iterable<CSVRecord> hRecords = CSVFormat.EXCEL.withIgnoreEmptyLines(true).withHeader("host_id", "host_name")
          .withFirstRecordAsHeader().withIgnoreSurroundingSpaces(true).parse(hostReader);

      for (CSVRecord record : hRecords) {
        nycHostBuilder.set("host_id", record.get("host_id"));
        nycHostBuilder.set("host_name", record.get("host_name"));
        final GenericData.Record hostRecord = nycHostBuilder.build();
        producer.send(new ProducerRecord<>(nycHostsTopic, null, hostRecord));
      }
      hostReader.close();
      /**
       * Produce airbnb room information record to NYCrooms topic. Read each line in
       * abnycroom.csv and parse records.
       */
      Reader roomReader = new FileReader("./resources/ab-nyc/ab-nyc-2019-room.csv");
      Iterable<CSVRecord> rRecords = CSVFormat.EXCEL.withIgnoreEmptyLines(true).withHeader("host_id", "host_name")
          .withFirstRecordAsHeader().withIgnoreSurroundingSpaces(true).parse(roomReader);
      roomReader.close();
      for (CSVRecord record : rRecords) {
        nycRoomBuilder.set("id", record.get("id"));
        nycRoomBuilder.set("name", record.get("name"));
        nycRoomBuilder.set("host_id", record.get("host_id"));
        nycRoomBuilder.set("neighbourhood_group", record.get("neighbourhood_group"));
        nycRoomBuilder.set("neighbourhood", record.get("neighbourhood"));
        nycRoomBuilder.set("latitude", record.get("latitude"));
        nycRoomBuilder.set("longitude", record.get("longitude"));
        nycRoomBuilder.set("room_type", record.get("room_type"));
        nycRoomBuilder.set("price", record.get("price"));
        nycRoomBuilder.set("minimum_nights", record.get("minimum_nights"));
        nycRoomBuilder.set("number_of_reviews", record.get("number_of_reviews"));
        nycRoomBuilder.set("last_reviews", record.get("last_reviews"));
        nycRoomBuilder.set("reviews_per_month", record.get("reviews_per_month"));
        nycRoomBuilder.set("calculated_host_listinngs_count", record.get("calculated_host_listinngs_count"));
        nycRoomBuilder.set("availability_365", record.get("id"));
        final GenericData.Record roomRecord = nycRoomBuilder.build();
        producer.send(new ProducerRecord<>(nycRoomsTopic, null, roomRecord));
      }
    }finally{

    }
  }

  private static Schema loadSchema(final String name) throws IOException {
    try (final InputStream input = Transform.class.getClassLoader()
        .getResourceAsStream("avro/com/takzok/kafka/" + name)) {
      return new Schema.Parser().parse(input);
    }
  }
}
